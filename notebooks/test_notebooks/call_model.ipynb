{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8fa6328-7120-4b29-ba2b-ff8704649ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython import get_ipython\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from skills_matcher.model_script import get_train_data, minibatch_model, niter_model, get_skills, PATH\n",
    "from skills_matcher.clean_data import clean_dictionary\n",
    "\n",
    "data = pd.read_csv(PATH + \"/data/dictionaries/new_dictionary.csv\")\n",
    "data = data[2000:]\n",
    "data = clean_dictionary(data, sample = None)\n",
    "df = pd.read_csv(PATH + '/data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1a80bca-0f52-459f-be55-de8b73fa2249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ensuring customers are at the heart of everything we do, making sure our expertise and medicines are easily accessed, providing patient services, dispensing, and giving healthcare advice. Leading, motivating, training and developing your colleagues. Keeping the both the customer and the business safe and legal. Building working relationships with Primary Care Networks and GP surgeries Ensuring payment claims are accurate for anything covered by the NHS. Using our modern planning systems to ensure we have the right number of colleagues and pharmacists on duty to meet customer needs , A Pharmacy Degree A passion for leading and empowering a team. Membership of the General Pharmaceutical Council (GPhC) Hepatitis B immunisation (or be prepared to be immunised after starting) Pharmacists working for Tesco will have to complete a DBS check (organised by Tesco) prior to commencement of employment. , Annual payment of your GPhC fee. A structured training plan for Pharmacy Leadership, crafted by industry specialists. Colleague Clubcard (including a 2nd card for a family member) after 3 months service with 10% off most purchases at Tesco. The Tesco Retirement Savings Plan. An annual bonus scheme, a share-save scheme and life assurance cover A secure, clean and safe environment for our colleagues to work. Discounts through the Tesco business, including Tesco Mobile & Tesco Financial products. For those requiring it, expert support and assistance through the application process for the new UK health and social care visa process. '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d06d0b5-f7e3-4591-8f2c-5925eaf7e5e0",
   "metadata": {},
   "source": [
    "## Minibatch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff269ea-e4c9-45fa-9423-a36f50d5faac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train_data = get_train_data(data)\n",
    "minibatch_model(train_data, 'minibatch_2', lang='en', pipe='ner', batch_size=1, drop=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d1f368-2afe-4d52-8030-2ec0b2d23330",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_minibatch = get_skills('minibatch_2', df.description[400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14dbdf3-1334-4c0c-aa81-26834d8adb74",
   "metadata": {},
   "source": [
    "## N_iter model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1fb14-34ef-4ae9-b647-b70840641fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "niter_model(train_data, 'n_iter', lang='en', pipe='ner', n_iter=1, drop=0.60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2c6a2a-0e2d-4445-8df8-6c2dcd50afb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_n_iter= get_skills('n_iter', df.description[340])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de38ac-99e7-4173-b23e-1cd7056f26ea",
   "metadata": {},
   "source": [
    "## Data Scientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02e87f01-f3a8-4184-af1f-9cff091099c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from skills_matcher.model_script import get_train_data, minibatch_model, niter_model, get_skills, PATH\n",
    "from skills_matcher.clean_data import clean_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c2311-6566-4654-884f-9057ddc29156",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv(PATH + \"/data/dictionaries/data_science_skills.csv\")\n",
    "data_2 = clean_dictionary(data_2, sample = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425eea91-65c9-484f-8d85-cbdf09c4f1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df = df.loc[df.job == 'data scientist']\n",
    "ds_df = ds_df.reset_index().drop(['index', 'Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdb7ac-d836-464e-a8ca-4739cb9f9768",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = get_train_data(data_2)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0598c1-2e98-48e5-8d91-f4f5cb4f0452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#minibatch_model(train_data, 'minibatch_4', lang='en', pipe='ner', batch_size=1, drop=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34820130-dcef-45a1-b6d1-d74080bad350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res_minibatch = get_skills('minibatch_4', ds_df.description[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69b70106-5294-43aa-8d73-681fde53b758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Long term opportunity of permanent Early Years Special Needs Teacher , SEN School , Full-time , Waltham Forest , Have experience as working as a Teacher in an SEN School , Have experience of Visual Impairment , Be able to travel to Waltham Forest , Available for full time and longer-term work , Have a DBS registered to the update service , Excellent daily rates paid weekly by our in-house Payroll team using the Pay As You Earn (PAYE) system. , Pension contributions (subject to a qualifying period). , Full compliance with AWR (Agency Workers' Regulations) , FREE training to help with your professional development , Generous refer a friend or colleague bonus scheme. , A dedicated consultant, who will provide ongoing support. \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.description[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509f205-0034-4796-bd7c-4e5468c4f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51a53cd2-eaca-4bb0-a43f-a51e49aecd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "JD = df.description.drop_duplicates()\n",
    "JD = JD.sample(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2fd1055-324e-4225-bccd-9f99bfe8ab2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "JD.to_csv('data_for_dom_dom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5b788b-28a8-4f30-8cb3-eade4e8f5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "JD = list(JD.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0b721f-40da-4c86-b1bd-c47aa9f9e293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c864b41-d8b4-4138-8401-7c0195b2859e",
   "metadata": {},
   "source": [
    "# Try Model with labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "263c8ada-d9ac-4ddb-a144-2449394f1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython import get_ipython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from skills_matcher.model_script import get_train_data, minibatch_model, niter_model, get_skills, PATH\n",
    "from skills_matcher.clean_data import clean_dictionary\n",
    "\n",
    "with open('annotation_data.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "from spacy import displacy\n",
    "from spacy.training import Example\n",
    "from spacy.training import biluo_tags_to_offsets\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import shutil\n",
    "import spacy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da0648ff-eef3-4799-9a07-853cc5313c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_format = []\n",
    "for i in range(len(data)):\n",
    "    jd = data[i]['data']\n",
    "    label = data[i]['label']\n",
    "    label = [tuple(j) for j in label] \n",
    "    label = {'entities': label}\n",
    "    row = (jd, label)\n",
    "    train_format.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "428de998-286d-4d20-8c14-bb61f407fb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████████████████▊           | 63/73 [00:00<00:00, 144.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 73/73 [00:00<00:00, 143.93it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "#nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\") # load other spacy model\n",
    "\n",
    "db = DocBin() # create a DocBin object\n",
    "\n",
    "for text, annot in tqdm(train_format): # data in previous format\n",
    "    doc = nlp.make_doc(text) # create doc object from text\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents # label the text with the ents\n",
    "    db.add(doc)\n",
    "\n",
    "db.to_disk(\"train.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ac338a3-eb25-4b00-9922-d406db350507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Examples of previous work. Strong attention to detail and grammar. Great communication skills. Access to a PC / Laptop with Microsoft Word, & email. 2 references. , Fully remote - work for us from anywhere around the UK. Competitive rates on a schedule to suit your lifestyle.',\n",
       " {'entities': [[2, 3, 'SKILL'], [6, 7, 'SKILL']]}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_format[0]\n",
    "\n",
    "label = data[0]['label']\n",
    "label = {'entities': [[2, 3, 'SKILL'], [6, 7, 'SKILL']]}\n",
    "jd = data[0]['data']\n",
    "train_format = [jd, label]\n",
    "train_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64f27882-5bc2-48b1-9fd0-ea3224eaa7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" High and low dusting, mopping, wiping and scrubbi...\" with entities \"[(63, 72, 'KNOWLEDGE'), (555, 582, 'SKILL'), (886,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "7it [00:00, 12.81it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" (restrictions apply in some instances due to the ...\" with entities \"[(794, 835, 'LEVEL'), (1463, 1477, 'KNOWLEDGE'), (...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" She/He is business product owner of the current i...\" with entities \"[(721, 725, 'SKILL'), (960, 977, 'KNOWLEDGE'), (12...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "9it [00:00,  8.59it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" To analyse samples to determine the toxicological...\" with entities \"[(246, 251, 'SKILL'), (253, 258, 'SKILL'), (260, 2...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "11it [00:01,  9.01it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" good academic performance at the MSc and PhD leve...\" with entities \"[(34, 45, 'LEVEL'), (767, 784, 'KNOWLEDGE'), (786,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "14it [00:01,  9.08it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" As a Machine Learning Engineer/Data Scientist*, y...\" with entities \"[(6, 46, 'KNOWLEDGE'), (477, 482, 'KNOWLEDGE'), (6...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "15it [00:01,  7.90it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" If you are a qualified bus driver with over 2 yea...\" with entities \"[(13, 34, 'KNOWLEDGE'), (40, 67, 'LEVEL')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "19it [00:02,  6.95it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" Build Pipelines from mapping from Data Analysts I...\" with entities \"[(1, 16, 'KNOWLEDGE'), (35, 48, 'KNOWLEDGE'), (458...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "20it [00:02,  7.58it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" Shape design solutions and rapidly visualize a pr...\" with entities \"[(127, 134, 'SKILL'), (331, 358, 'SKILL'), (541, 5...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "21it [00:02,  6.47it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" Manage the deployment processes Deploy of our ETW...\" with entities \"[(261, 275, 'SKILL'), (356, 370, 'SKILL'), (505, 5...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "30it [00:04,  7.08it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" Assisting project management during final factory...\" with entities \"[(565, 594, 'LEVEL'), (598, 620, 'KNOWLEDGE'), (62...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "32it [00:04,  5.67it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" Assemble large, complex datasets Identify, design...\" with entities \"[(300, 303, 'SKILL'), (319, 331, 'SKILL'), (548, 5...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "33it [00:04,  4.95it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" Managing all aspects of geological assessment pro...\" with entities \"[(375, 404, 'KNOWLEDGE'), (704, 707, 'LEVEL'), (76...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "35it [00:05,  4.02it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" Processing payments, invoices, incomes and receip...\" with entities \"[(613, 616, 'LEVEL'), (620, 623, 'LEVEL'), (633, 6...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "36it [00:05,  4.01it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" Responsible for conducting accounting for multipl...\" with entities \"[(28, 38, 'KNOWLEDGE'), (98, 107, 'KNOWLEDGE'), (1...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "38it [00:05,  4.75it/s]/home/macrodrigues/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/training/iob_utils.py:141: UserWarning: [W030] Some entities could not be aligned in the text \" Build relationships across numerous clinical and ...\" with entities \"[(686, 705, 'KNOWLEDGE'), (963, 967, 'LEVEL'), (97...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "40it [00:06,  6.32it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the `debug data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug data --help",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9699/1085701477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mminibatch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'minibatch_4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/code/macrodrigues/skills_matcher/skills_matcher/model_script.py\u001b[0m in \u001b[0;36mminibatch_model\u001b[0;34m(train_data, model_name, lang, pipe, batch_size, drop)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# Update the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 nlp.update([example],\n\u001b[0m\u001b[1;32m     56\u001b[0m                             \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                             \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[1;32m   1150\u001b[0m             \u001b[0;31m# ignore statements are used here because mypy ignores hasattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 if (\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/pipeline/transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/pipeline/transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser._init_gold_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/spacy/pipeline/_parser_internals/transition_system.pyx\u001b[0m in \u001b[0;36mspacy.pipeline._parser_internals.transition_system.TransitionSystem.get_oracle_sequence_from_state\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the `debug data` command to validate your JSON-formatted training data. For details, run:\npython -m spacy debug data --help"
     ]
    }
   ],
   "source": [
    "minibatch_model(train_format, 'minibatch_4', lang='en', pipe='ner', batch_size=1, drop=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d1789be-0f43-457e-87fa-fe9938528e72",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9699/4288747178.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ment\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'entities'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "labels = ['KNOWLEDGE', 'MIN_EXP', 'LABEL', 'SKILL']\n",
    "\n",
    "nlp = spacy.blank('en')  #create a blank model in english\n",
    "\n",
    "# set pipeline\n",
    "nlp.add_pipe('ner') # ner is an entity recognizer, detects labels.\n",
    "\n",
    "\n",
    "for _, annotations in train_format:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# apply n_iter model\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(2):\n",
    "        np.random.shuffle(train_format)\n",
    "        losses = {}\n",
    "        for text, annotations in tqdm(train_format):\n",
    "            doc = nlp.make_doc(text)\n",
    "            # Update the model\n",
    "            print(annotations)\n",
    "            example = Example.from_dict(doc, *annotations)\n",
    "            # Update the model\n",
    "            nlp.update([example],\n",
    "                        sgd = optimizer,\n",
    "                        losses=losses,\n",
    "                        drop=drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae7f267-7d92-403e-b276-82fb84302aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
